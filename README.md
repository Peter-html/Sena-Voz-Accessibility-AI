# Sena Voz â€“ Sign Language Gesture Communication ğŸ¤ŸğŸ—£ï¸

Sena Voz is an **AI-powered accessibility project** designed to bridge the communication gap for **blind and speech-impaired users** through **sign language gesture recognition**.  
The system converts hand gestures into **text and voice output**, enabling inclusive communication on digital platforms. It also includes a **learning module** to help users practice and master sign language.

---

## ğŸŒ Problem Statement

People with visual and speech impairments often face challenges while communicating on online platforms.  
Existing solutions are either expensive, complex, or lack real-time accessibility support.

**Sena Voz aims to solve this by providing a simple, real-time, and accessible gesture-based communication system.**

---

## âœ¨ Features

- ğŸ¥ **Real-time Sign Language Gesture Recognition**
- ğŸ”Š **Text-to-Speech Output** for blind users
- ğŸ“š **Learning Module** for practicing sign language
- â™¿ **Accessibility-first design**
- âš¡ Lightweight and easy to run
- ğŸ§  ML-ready architecture (can be extended)

---

## ğŸ› ï¸ Tech Stack

- **Language:** Python  
- **Libraries & Tools:**
  - OpenCV â€“ Video capture & processing
  - MediaPipe â€“ Hand landmark detection
  - NumPy â€“ Data handling
  - pyttsx3 â€“ Text-to-Speech (offline)

---

## ğŸ§  System Architecture

1. Webcam captures hand gestures  
2. MediaPipe detects hand landmarks  
3. Gesture recognition logic identifies the sign  
4. Output is converted to:
   - Text (displayed on screen)
   - Voice (audio feedback)
5. Learning module assists users in practicing gestures  

---

## ğŸ“ Project Structure

